{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum AI Intraday Risk Modeling Demo\n",
    "\n",
    "This notebook demonstrates the integration of live data ingestion, AI-based volatility prediction, and quantum optimization for real-time intraday risk modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Import required functions from scripts\n",
    "from scripts.data_ingestion import get_data\n",
    "from scripts.lstm_prediction import train_lstm\n",
    "from scripts.quantum_optimization import quantum_optimization, display_results\n",
    "from scripts.integrated_solution import integrated_workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Fetch Data (Live or Mock)\n",
    "\n",
    "Use the `get_data` function to fetch market data, either live from Bloomberg API or mock data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mock data for demonstration purposes.\n",
      "                 time        open        high         low       close  volume\n",
      "0 2024-12-29 09:30:00  178.257334  202.162842   91.140842  127.161649    1257\n",
      "1 2024-12-29 09:31:00  178.764110  200.520526  136.327013  193.899046    2758\n",
      "2 2024-12-29 09:32:00  147.227448  228.903800  111.672585  193.579223    1762\n",
      "3 2024-12-29 09:33:00  147.302680  196.603246  115.777358  152.673235    4334\n",
      "4 2024-12-29 09:34:00  198.107508  160.199942  106.629228  106.536825    3496\n"
     ]
    }
   ],
   "source": [
    "# Fetch market data\n",
    "ticker = \"AAPL US Equity\"\n",
    "start_time = \"2024-12-29T09:30:00\"\n",
    "end_time = \"2024-12-29T16:00:00\"\n",
    "\n",
    "df = get_data(ticker, start_time, end_time)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Predict Volatility Using LSTM\n",
    "\n",
    "Train an LSTM model on the `close` prices from the fetched data to predict market volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for LSTM model...\n",
      "Input Shape: (381, 10, 1), Output Shape: (381,)\n",
      "\n",
      "Defining the LSTM model...\n",
      "Model compiled successfully.\n",
      "\n",
      "Training the LSTM model...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mukundpandey/anaconda3/envs/quantum_ai_demo/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 22402.8145\n",
      "Epoch 2/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21225.1113 \n",
      "Epoch 3/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21654.4980 \n",
      "Epoch 4/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20379.9219 \n",
      "Epoch 5/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19749.6602 \n",
      "Model training completed.\n",
      "\n",
      "Generating predictions...\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "Predicted Volatility: [10.662489]\n"
     ]
    }
   ],
   "source": [
    "# Train LSTM and predict volatility\n",
    "price_data = df['close'].values\n",
    "predictions = train_lstm(price_data, time_steps=10, epochs=5, batch_size=32)\n",
    "\n",
    "print(\"Predicted Volatility:\", predictions[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Quantum Optimization\n",
    "\n",
    "Solve a QUBO problem using the `quantum_optimization` function to optimize portfolio adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running quantum optimization with USE_MOCK_QUANTUM = False\n",
      "Initializing the quantum sampler...\n",
      "Submitting QUBO to the quantum annealer...\n",
      "Quantum optimization completed. Processing results...\n",
      "\n",
      "Quantum Optimization Results:\n",
      "Sample: {'Position_1': 1, 'Position_2': 1}, Energy: -0.25000000000000006\n"
     ]
    }
   ],
   "source": [
    "# Toggle between real and mock quantum optimization\n",
    "USE_MOCK_QUANTUM = False  # Set this to True for mock results, False for real quantum optimization\n",
    "\n",
    "# Define a sample QUBO problem\n",
    "qubo = {\n",
    "    ('Position_1', 'Position_1'): -0.1,  # Self-loop (diagonal term)\n",
    "    ('Position_1', 'Position_2'): 0.05,  # Interaction term\n",
    "    ('Position_2', 'Position_2'): -0.2   # Self-loop (diagonal term)\n",
    "}\n",
    "\n",
    "# Solve the QUBO problem\n",
    "print(f\"Running quantum optimization with USE_MOCK_QUANTUM = {USE_MOCK_QUANTUM}\")\n",
    "result = quantum_optimization(qubo)\n",
    "\n",
    "# Display results\n",
    "display_results(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Integrated Workflow\n",
    "\n",
    "Combine live data, AI predictions, and quantum optimization for a seamless risk management workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Fetching market data...\n",
      "Using mock data for demonstration purposes.\n",
      "Fetched 391 rows of data.\n",
      "\n",
      "Step 2: Predicting volatility using AI...\n",
      "Preparing data for LSTM model...\n",
      "Input Shape: (381, 10, 1), Output Shape: (381,)\n",
      "\n",
      "Defining the LSTM model...\n",
      "Model compiled successfully.\n",
      "\n",
      "Training the LSTM model...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mukundpandey/anaconda3/envs/quantum_ai_demo/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 23093.6016\n",
      "Epoch 2/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22540.7305 \n",
      "Epoch 3/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22073.8965 \n",
      "Epoch 4/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20956.9805 \n",
      "Epoch 5/5\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 20895.9844 \n",
      "Model training completed.\n",
      "\n",
      "Generating predictions...\n",
      "\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x300340a40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
      "Predicted Volatility: 10.97203540802002\n",
      "\n",
      "Step 3: Adjusting QUBO based on predictions...\n",
      "Adjusted QUBO: {('Position_1', 'Position_1'): -1.097203540802002, ('Position_1', 'Position_2'): 0.548601770401001, ('Position_2', 'Position_2'): -2.194407081604004}\n",
      "\n",
      "Step 4: Solving QUBO with Quantum Optimization...\n",
      "Initializing the quantum sampler...\n",
      "Submitting QUBO to the quantum annealer...\n",
      "Quantum optimization completed. Processing results...\n",
      "\n",
      "Quantum Optimization Results:\n",
      "\n",
      "Sample: {'Position_1': 1, 'Position_2': 1}, Energy: -2.7430088520050053\n",
      "Integrated Workflow Results:\n",
      "Sample: {'Position_1': 1, 'Position_2': 1}, Energy: -2.7430088520050053\n"
     ]
    }
   ],
   "source": [
    "# Run the integrated workflow\n",
    "result = integrated_workflow(ticker, start_time, end_time, qubo)\n",
    "\n",
    "print(\"Integrated Workflow Results:\")\n",
    "for sample, energy in result.data(['sample', 'energy']):\n",
    "    print(f\"Sample: {sample}, Energy: {energy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum_ai_demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
